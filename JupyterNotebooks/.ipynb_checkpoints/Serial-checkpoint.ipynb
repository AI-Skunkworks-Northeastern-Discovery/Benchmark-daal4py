{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16186bdb",
   "metadata": {},
   "source": [
    "import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917ba08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which: no fi_info in (/home/ullal.m/miniconda3/bin:/shared/centos7/discovery/bin:/home/ullal.m/miniconda3/envs/daal4py/bin:/shared/centos7/anaconda3/3.7/condabin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/home/ullal.m/.local/bin:/home/ullal.m/bin)\n",
      "which: no fi_info in (/home/ullal.m/miniconda3/bin:/shared/centos7/discovery/bin:/home/ullal.m/miniconda3/envs/daal4py/bin:/shared/centos7/anaconda3/3.7/condabin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/home/ullal.m/.local/bin:/home/ullal.m/bin)\n"
     ]
    }
   ],
   "source": [
    "!source /home/ullal.m/miniconda3/bin/activate\n",
    "!activate daal4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f29f9199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/ullal.m/miniconda3/envs/daal4py:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "argon2-cffi               20.1.0           py37h27cfd23_1  \r\n",
      "async_generator           1.10             py37h28b3542_0  \r\n",
      "attrs                     20.3.0             pyhd3eb1b0_0  \r\n",
      "backcall                  0.2.0                      py_0    anaconda\r\n",
      "bleach                    3.3.0              pyhd3eb1b0_0  \r\n",
      "brotlipy                  0.7.0           py37h27cfd23_1003  \r\n",
      "bzip2                     1.0.8                h88c068d_5    intel\r\n",
      "ca-certificates           2021.4.13            h06a4308_1  \r\n",
      "certifi                   2020.12.5        py37h06a4308_0  \r\n",
      "cffi                      1.14.5           py37h261ae71_0  \r\n",
      "chardet                   4.0.0           py37h06a4308_1003  \r\n",
      "cryptography              3.1              py37h1ba5d50_0  \r\n",
      "cycler                    0.10.0                     py_2    conda-forge\r\n",
      "daal                      2020.3                intel_304    intel\r\n",
      "daal4py                   2020.3           py37h2543e53_1    intel\r\n",
      "dbus                      1.13.6               he372182_0    conda-forge\r\n",
      "decorator                 4.4.2                      py_0    conda-forge\r\n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \r\n",
      "entrypoints               0.3                      py37_0  \r\n",
      "expat                     2.2.9                he1b5a44_2    conda-forge\r\n",
      "fontconfig                2.13.1            he4413a7_1000    conda-forge\r\n",
      "freetype                  2.10.4               h7ca028e_0    conda-forge\r\n",
      "glib                      2.66.1               h92f7085_0    anaconda\r\n",
      "gst-plugins-base          1.14.0               hbbd80ab_1  \r\n",
      "gstreamer                 1.14.0               hb31296c_0  \r\n",
      "icc_rt                    2020.3                intel_304    intel\r\n",
      "icu                       58.2              hf484d3e_1000    conda-forge\r\n",
      "idna                      2.10               pyhd3eb1b0_0  \r\n",
      "impi_rt                   2019.9                intel_304    intel\r\n",
      "importlib-metadata        3.7.3            py37h06a4308_1  \r\n",
      "importlib_metadata        3.7.3                hd3eb1b0_1  \r\n",
      "intel-openmp              2020.3                intel_304    intel\r\n",
      "intelpython               2020.4                        0    intel\r\n",
      "ipykernel                 5.3.4            py37h5ca1d4c_0    anaconda\r\n",
      "ipython                   7.18.1           py37h5ca1d4c_0    anaconda\r\n",
      "ipython_genutils          0.2.0                    py37_0    anaconda\r\n",
      "jedi                      0.17.2                   py37_0    anaconda\r\n",
      "jinja2                    2.11.3             pyhd3eb1b0_0  \r\n",
      "joblib                    0.17.0                   pypi_0    pypi\r\n",
      "jpeg                      9d                   h36c2ea0_0    conda-forge\r\n",
      "json5                     0.9.5                      py_0  \r\n",
      "jsonschema                3.2.0                      py_2  \r\n",
      "jupyter_client            6.1.7                      py_0    conda-forge\r\n",
      "jupyter_core              4.6.3                    py37_0    conda-forge\r\n",
      "jupyterlab                1.0.2            py37hf63ae98_0  \r\n",
      "jupyterlab_pygments       0.1.2                      py_0  \r\n",
      "jupyterlab_server         1.2.0                      py_0  \r\n",
      "kiwisolver                1.3.1            py37hc928c03_0    conda-forge\r\n",
      "libblas                   3.9.0                2_openblas    conda-forge\r\n",
      "libcblas                  3.9.0                2_openblas    conda-forge\r\n",
      "libffi                    3.3                 h07ac4c1_12    intel\r\n",
      "libgcc-ng                 9.1.0                hdf63c60_0    intel\r\n",
      "libgfortran-ng            7.5.0               hae1eefd_17    conda-forge\r\n",
      "libgfortran4              7.5.0               hae1eefd_17    conda-forge\r\n",
      "liblapack                 3.9.0                2_openblas    conda-forge\r\n",
      "libopenblas               0.3.12          pthreads_hb3c22a3_1    conda-forge\r\n",
      "libpng                    1.6.37               h21135ba_2    conda-forge\r\n",
      "libsodium                 1.0.18               h7b6447c_0    anaconda\r\n",
      "libstdcxx-ng              9.1.0                hdf63c60_0    intel\r\n",
      "libtiff                   4.1.0                h4f3a223_6    conda-forge\r\n",
      "libuuid                   2.32.1            h14c3975_1000    conda-forge\r\n",
      "libwebp-base              1.1.0                h36c2ea0_3    conda-forge\r\n",
      "libxcb                    1.13              h14c3975_1002    conda-forge\r\n",
      "libxml2                   2.9.10               hb55368b_3    anaconda\r\n",
      "llvmlite                  0.35.0                   pypi_0    pypi\r\n",
      "lz4-c                     1.9.2                he1b5a44_3    conda-forge\r\n",
      "markupsafe                1.1.1            py37h14c3975_1  \r\n",
      "matplotlib                3.3.2            py37hc8dfbb8_1    conda-forge\r\n",
      "matplotlib-base           3.3.2            py37h817c723_0  \r\n",
      "memory_profiler           0.58.0                     py_0    conda-forge\r\n",
      "mistune                   0.8.4           py37h14c3975_1001  \r\n",
      "mkl                       2020.4                intel_304    intel\r\n",
      "mkl-service               2.3.0            py37h43c2ffe_6    intel\r\n",
      "mkl_fft                   1.2.0            py37h3aece79_1    intel\r\n",
      "mkl_random                1.2.0            py37h0107b67_1    intel\r\n",
      "mkl_umath                 0.0.1            py37h0dca2b4_1    intel\r\n",
      "nbclient                  0.5.3              pyhd3eb1b0_0  \r\n",
      "nbconvert                 6.0.7                    py37_0  \r\n",
      "nbformat                  5.1.2              pyhd3eb1b0_1  \r\n",
      "nest-asyncio              1.5.1              pyhd3eb1b0_0  \r\n",
      "notebook                  6.3.0            py37h06a4308_0  \r\n",
      "numba                     0.52.0                   pypi_0    pypi\r\n",
      "numpy                     1.18.5          py37hafab738_19    intel\r\n",
      "numpy-base                1.18.5          py37hf11705a_19    intel\r\n",
      "olefile                   0.46               pyh9f0ad1d_1    conda-forge\r\n",
      "openssl                   1.1.1g               h7b6447c_0  \r\n",
      "packaging                 20.9               pyhd3eb1b0_0  \r\n",
      "pandas                    1.1.3            py37he6710b0_0    anaconda\r\n",
      "pandoc                    2.12                 h06a4308_0  \r\n",
      "pandocfilters             1.4.3            py37h06a4308_1  \r\n",
      "parso                     0.7.0                      py_0    anaconda\r\n",
      "pcre                      8.44                 he1b5a44_0    conda-forge\r\n",
      "pexpect                   4.8.0                    py37_1    anaconda\r\n",
      "pickleshare               0.7.5                 py37_1001    anaconda\r\n",
      "pillow                    6.2.1            py37hd70f55b_1    conda-forge\r\n",
      "pip                       20.2.2           py37h01fe7e7_1    intel\r\n",
      "prometheus_client         0.9.0              pyhd3eb1b0_0  \r\n",
      "prompt-toolkit            3.0.8                      py_0    conda-forge\r\n",
      "psutil                    5.7.3            py37hb5d75c8_0    conda-forge\r\n",
      "pthread-stubs             0.4               h14c3975_1001    conda-forge\r\n",
      "ptyprocess                0.6.0                    py37_0    conda-forge\r\n",
      "pycparser                 2.20                       py_2  \r\n",
      "pygments                  2.7.1                      py_0    conda-forge\r\n",
      "pyopenssl                 20.0.1             pyhd3eb1b0_1  \r\n",
      "pyparsing                 2.4.7              pyh9f0ad1d_0    conda-forge\r\n",
      "pyqt                      5.9.2            py37hcca6a23_4    conda-forge\r\n",
      "pyrsistent                0.17.3           py37h7b6447c_0  \r\n",
      "pysocks                   1.7.1                    py37_1  \r\n",
      "python                    3.7.7               h7f0eb4e_22    intel\r\n",
      "python-dateutil           2.8.1                      py_0    conda-forge\r\n",
      "python_abi                3.7                     1_cp37m    conda-forge\r\n",
      "pytz                      2020.1                     py_0    anaconda\r\n",
      "pyzmq                     19.0.2           py37he6710b0_1    anaconda\r\n",
      "qt                        5.9.7                h5867ecd_1  \r\n",
      "requests                  2.25.1             pyhd3eb1b0_0  \r\n",
      "scikit-learn              0.23.2                   pypi_0    pypi\r\n",
      "scipy                     1.5.3            py37h8911b10_0    conda-forge\r\n",
      "send2trash                1.5.0              pyhd3eb1b0_1  \r\n",
      "setuptools                49.6.0           py37hf90b819_1    intel\r\n",
      "shap                      0.37.0                   pypi_0    pypi\r\n",
      "sip                       4.19.8           py37hf484d3e_0    anaconda\r\n",
      "six                       1.15.0           py37h240e974_1    intel\r\n",
      "slicer                    0.0.3                    pypi_0    pypi\r\n",
      "sqlite                    3.33.0               h88c068d_1    intel\r\n",
      "tbb                       2020.3                intel_304    intel\r\n",
      "tbb4py                    2020.3             py37_intel_1    intel\r\n",
      "tcl                       8.6.9               h14c3975_27    intel\r\n",
      "terminado                 0.9.3            py37h06a4308_0  \r\n",
      "testpath                  0.4.4              pyhd3eb1b0_0  \r\n",
      "threadpoolctl             2.1.0                    pypi_0    pypi\r\n",
      "tk                        8.6.9                        29    intel\r\n",
      "tornado                   6.0.4            py37h7b6447c_1    anaconda\r\n",
      "tqdm                      4.54.0                   pypi_0    pypi\r\n",
      "traitlets                 5.0.5                      py_0    conda-forge\r\n",
      "typing_extensions         3.7.4.3            pyha847dfd_0  \r\n",
      "urllib3                   1.26.4             pyhd3eb1b0_0  \r\n",
      "wcwidth                   0.2.5                      py_0    anaconda\r\n",
      "webencodings              0.5.1                    py37_1  \r\n",
      "wheel                     0.35.1           py37ha0f1a1d_1    intel\r\n",
      "xgboost                   1.2.1                    pypi_0    pypi\r\n",
      "xorg-libxau               1.0.9                h14c3975_0    conda-forge\r\n",
      "xorg-libxdmcp             1.1.3                h516909a_0    conda-forge\r\n",
      "xz                        5.2.5                hcc43529_1    intel\r\n",
      "zeromq                    4.3.3                he6710b0_3    anaconda\r\n",
      "zipp                      3.4.1              pyhd3eb1b0_0  \r\n",
      "zlib                      1.2.11.1             hb8a9d29_2    intel\r\n",
      "zstd                      1.4.5                h6597ccf_2    conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4b3fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: where: command not found\r\n"
     ]
    }
   ],
   "source": [
    "!where python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf9d0c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fb213d9fcae5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import config\n",
    "import sys\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from lib.serial_a import Serial_a\n",
    "from lib.serial_b import Serial_b\n",
    "from lib.parallel_a import Parallel_a\n",
    "from lib.parallel_b import Parallel_b\n",
    "from lib.Numeric import Numeric\n",
    "from lib.Input_Output_files_functions import Input_Ouput_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95937fc",
   "metadata": {},
   "source": [
    "class to convert the data into numeric data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a4e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Numeric():\n",
    "\n",
    "    def __init__(self, latency):\n",
    "        self.latency = latency\n",
    "\n",
    "    def convert_to_numeric(self, df,target,classification = True):\n",
    "\n",
    "        # getting categorical, continous dtypes and  boolean dtypes\n",
    "\n",
    "        categorical_columns = df.select_dtypes(include=['object']).columns.to_list()\n",
    "\n",
    "        bool_columns = df.select_dtypes(include=['bool']).columns.to_list()\n",
    "\n",
    "        continou_columns = df.select_dtypes(exclude=['object']).columns.to_list()\n",
    "\n",
    "        continous_columns = [x for x in continou_columns if not x in bool_columns]\n",
    "\n",
    "        # convert boolean into numerical values\n",
    "        for col in bool_columns:\n",
    "            df[col] = df[col].astype(int)\n",
    "\n",
    "        print(\"Continous\",continous_columns)\n",
    "\n",
    "        # handling missing values\n",
    "        for col in categorical_columns:\n",
    "            df[col] = df[col].fillna(df[col].mode())\n",
    "        for col in continous_columns:\n",
    "            df[col] = df[col].fillna(df[col].mean())\n",
    "        for col in bool_columns:\n",
    "            df[col] = df[col].fillna(df[col].mode())\n",
    "\n",
    "        if target in continous_columns: continous_columns.remove(target)\n",
    "\n",
    "\n",
    "        for col in continous_columns:\n",
    "            if len(df[col].unique())==2:\n",
    "                continous_columns.remove(col)\n",
    "\n",
    "        # Create x, where x the 'scores' column's values as floats\n",
    "        x = df[continous_columns].values.astype(float)\n",
    "\n",
    "        # Create a minimum and maximum processor object\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "        # Create an object to transform the data to fit minmax processor\n",
    "        x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "        # Run the normalizer on the dataframe\n",
    "        df[continous_columns] = pd.DataFrame(x_scaled)\n",
    "\n",
    "        # dict\n",
    "        df_dict = {}\n",
    "\n",
    "        print(\"before for\", categorical_columns)\n",
    "\n",
    "\n",
    "        # label encode the columns with two categorical values\n",
    "        for col in categorical_columns:            \n",
    "            if len(df[col].unique())>=2:\n",
    "                print(col ,' - ', len(df[col].unique()))\n",
    "                df[col] = df[col].astype(\"category\")\n",
    "                df_dict[col] = dict(\n",
    "                    enumerate(df[col].cat.categories))\n",
    "                df[col] = df[col].cat.codes\n",
    "\n",
    "        if target in categorical_columns: categorical_columns.remove(target)\n",
    "\n",
    "        unwated_cols = []\n",
    "\n",
    "        '''\n",
    "        Remove columns with too \n",
    "        many unqiue values in \n",
    "        categorical columns to \n",
    "        reduce the space of the data\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        for col in categorical_columns:\n",
    "\n",
    "            l = len(df[col].unique())    \n",
    "            if l>5:\n",
    "                unwated_cols.append(col)\n",
    "\n",
    "        df = df.drop(unwated_cols,axis = 1)\n",
    "        updated_cat_columns = [x for x in categorical_columns if not x in unwated_cols ]\n",
    "\n",
    "\n",
    "        '''\n",
    "        Generate dummy variables\n",
    "        for the categorical columns\n",
    "        '''\n",
    "        \n",
    "        if updated_cat_columns:\n",
    "            data=pd.get_dummies(df[updated_cat_columns])\n",
    "            data = data.apply(np.int64)\n",
    "            df=df.drop(updated_cat_columns ,axis = 1)\n",
    "            df = df.join(data)\n",
    "\n",
    "        return df,df_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d94b53",
   "metadata": {},
   "source": [
    "details of the dataset and the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ee632",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './data/'\n",
    "\n",
    "# read the data from the user\n",
    "keys = config.parameters['keys']\n",
    "key = keys[0]\n",
    "print('All available datasets \\n', keys)\n",
    "print('Dataset to train is: ', key)\n",
    "\n",
    "# get the number of thereads from the user\n",
    "num = config.parameters['num']\n",
    "print(\"Num of threads is: \", num)\n",
    "\n",
    "#classification = config.parameters['classification']\n",
    "classification = 2\n",
    "print('Classification: 1 - True and 2 - False, selected option', classification)\n",
    "\n",
    "# ask the user whether he wants to run parallel or serial\n",
    "type_key = '1'\n",
    "print(\"Tye of run: 1 - serial and 2 - parallel, selected option\", type_key)\n",
    "\n",
    "targets = config.parameters['targets']\n",
    "target = targets[0]\n",
    "print('Target for the Datasets: ', target)\n",
    "\n",
    "environment = 'global'\n",
    "print('Running environment: ', environment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce248c9",
   "metadata": {},
   "source": [
    "create the dataframe/datastructure from the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6314bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y-%m-%d__%H.%M\")\n",
    "type_key_str = '_Serial_' if type_key == \"1\" else '_Parallel_'\n",
    "type_key_str = type_key_str\n",
    "\n",
    "# declaring variables and data structures\n",
    "# latency dictionary to hold execution times of individual functions\n",
    "latency = dict()\n",
    "# metric dictionary\n",
    "metrics = dict()\n",
    "\n",
    "# read the data from the data floder\n",
    "data = pd.read_csv(\"data/\" + key + \".csv\", encoding= 'unicode_escape', error_bad_lines=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937c9de0",
   "metadata": {},
   "source": [
    "fill empty values, which otherwise will be problematic for the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8e544",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n The columns present are\\n\\n\", data.columns)\n",
    "list_cols = data.columns.to_list()\n",
    "if target in list_cols:\n",
    "    if data[target].isnull().sum() == 0:\n",
    "        pass\n",
    "    else:\n",
    "        data[target] = data[target].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5a0069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    '''\n",
    "    This funtion helps to generate the data\n",
    "    required for multiprocessing\n",
    "    '''\n",
    "    num = data.shape\n",
    "    num_each = round(num[0]/3)\n",
    "\n",
    "    l = 0\n",
    "    nums = num_each\n",
    "\n",
    "    for i in range(3):\n",
    "        df = data[l:nums]\n",
    "        l += num_each\n",
    "        nums += num_each\n",
    "        if nums > num[0]:\n",
    "            nums = num[0]\n",
    "        filename = './dist_data/' + key + '_'+str(i+1)+'.csv'\n",
    "        df.to_csv(filename, index=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c75c4",
   "metadata": {},
   "source": [
    "alter the data loaded from the files using Numeric class to get all the values as Numeric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ff907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating object for numeric\n",
    "numthreads = int(num)\n",
    "num = Numeric(latency)\n",
    "\n",
    "flag = True if classification == '1' else False\n",
    "\n",
    "df, dict_df = num.convert_to_numeric(data, target, flag)\n",
    "print(df.shape)\n",
    "\n",
    "# creating data for distrubuted processing in Pydaal\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train = df[msk]\n",
    "test = df[~msk]\n",
    "filename = './dist_data/' + key + '_test'+'.csv'\n",
    "test.to_csv(filename, index=False)\n",
    "data_split(train)\n",
    "\n",
    "feature = df.columns.tolist()\n",
    "feature.remove(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedcc9c",
   "metadata": {},
   "source": [
    "install the libarary used to save the results onto MS excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9bcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff787408",
   "metadata": {},
   "source": [
    "Run the standard set of algorithms on the selected dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12df54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "CPU = '1'\n",
    "Memory = '100'\n",
    "\n",
    "target_file = './SerialRun-Results-' + key + '-' + environment + '.xlsx'\n",
    "check_folder = os.path.isdir(target_file)\n",
    "\n",
    "if classification != 1:\n",
    "    columns = ['CPU',\n",
    "     'Memory',\n",
    "     'NumThreads',\n",
    "     'LinearRegression',\n",
    "     'LinearRegression_sk',\n",
    "     'RidgeRegression',\n",
    "     'RidgeRegression_sk',\n",
    "     'PCA',\n",
    "     'SVD',\n",
    "     'MSE_LinearRegression',\n",
    "     'r2score_LinearRegression',\n",
    "     'MSE_LinearRegression_sk',\n",
    "     'r2score_LinearRegression_sk',\n",
    "     'MSE_RidgeRegression',\n",
    "     'r2score_RidgeRegression',\n",
    "     'MSE_RidgeRegression_sk',\n",
    "     'r2score_RidgeRegression_sk']\n",
    "elif classification == 1:\n",
    "    columns = ['CPU',\n",
    "     'Memory',\n",
    "     'NumThreads',\n",
    "     'NaiveBayes',\n",
    "     'PCA',\n",
    "     'SVD']\n",
    "\n",
    "if not check_folder:\n",
    "    wb = Workbook()\n",
    "    ws = wb.active\n",
    "    ws.append(columns)\n",
    "    wb.save(target_file) \n",
    "\n",
    "def one_loop():\n",
    "    serial_a = Serial_a(latency, metrics)\n",
    "    serial_b = Serial_b(latency, metrics)\n",
    "\n",
    "    X_train = train[feature]\n",
    "    y_train = train[target]\n",
    "    X_test = test[feature]\n",
    "    y_test = test[target]\n",
    "    \n",
    "    # Naive bayes\n",
    "    if classification == 1:\n",
    "        serial_a.naiveBayes(X_train, X_test, y_train, y_test, target)\n",
    "\n",
    "    else:\n",
    "        # linear Regression\n",
    "        serial_a.linearRegression(X_train, X_test, y_train, y_test, target)\n",
    "\n",
    "        # sklearn linear Regression\n",
    "        serial_a.serial_linear_sk_learn(X_train, X_test, y_train, y_test, target)\n",
    "\n",
    "        # Ridge Regression\n",
    "        serial_b.ridgeRegression(X_train, X_test, y_train, y_test, target)\n",
    "\n",
    "        # sklearn Ridge Regression\n",
    "        serial_b.sklearn_ridgeRegression(X_train, X_test, y_train, y_test, target)\n",
    "\n",
    "\n",
    "    # K-means Regression\n",
    "    #serial_b.kMeans(df, target)\n",
    "\n",
    "    # PCA Regression\n",
    "    serial_a.pca(df, target)\n",
    "\n",
    "    # SVD Regression\n",
    "    serial_b.svd(df, target)\n",
    "    \n",
    "    wb = load_workbook(target_file)\n",
    "    ws = wb.active\n",
    "    data = list(serial_a.latency.values()) + list(serial_a.metrics.values())\n",
    "    data.insert(0, numthreads)\n",
    "    data.insert(0, Memory)\n",
    "    data.insert(0, CPU)\n",
    "    ws.append(data)\n",
    "    wb.save(target_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccf8c83",
   "metadata": {},
   "source": [
    "all the algorithms are grouped into a function such that, the function can be run 100 times and the result be monitored. We do this to ensure that each run gives us consistent results and that the results are reproducable using the software and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    one_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4944f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# values seen here are the run time of the algorithm\n",
    "\n",
    "hundred_runs = pd.read_excel(target_file, engine='openpyxl')\n",
    "hundred_runs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77fe967",
   "metadata": {},
   "outputs": [],
   "source": [
    "hundred_runs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a89e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "columns = ['LinearRegression', 'LinearRegression_sk', 'RidgeRegression', 'RidgeRegression_sk', 'PCA', 'SVD']\n",
    "\n",
    "_, ax = plt.subplots(1,6, figsize=(20,5))\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    \n",
    "    y1 = list(hundred_runs[column])\n",
    "    x1 = np.arange(len(y1))\n",
    "    #y2 = list(all_latency2[column])\n",
    "\n",
    "    ax[i].plot(x1,y1, label = 'local')    \n",
    "    #ax[i].bar(x2+0.3,y2, width=0.3, label = 'global')\n",
    "    #ax[i].set_xticklabels(x1, rotation=10)\n",
    "    ax[i].set_xlabel('Runs')\n",
    "    ax[i].set_ylabel('Run Time')\n",
    "    ax[i].legend()\n",
    "    ax[i].title.set_text(column)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
